---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I'm a Senior Researcher at [Shenzhen University of Advanced Technology](https://www.suat-sz.edu.cn/), and I work closely with [Prof. Min Yang](https://minyang.me/). My research interests include artificial intelligence, natural language processing, large language models, discourse parsing, dialogue systems, and summarization. Before that, I was a postdoc research fellow at [School of Data Science](https://sds.cuhk.edu.cn/), [The Chinese University of Hong Kong, Shenzhen](https://www.cuhk.edu.cn/en), and worked with [Prof. Haizhou Li](https://colips.org/~eleliha/) and [Prof. Benyou Wang](https://wabyking.github.io/old.html) to research LLMs.

I serve as a (Sinor) Area Chair in ACL Rolling Review, Senior Area Chair (Discourse and Pragmatics) in IJCNLP-AACL 2025, the Area Chair (Discourse and Pragmatics) in EMNLP 2023, and the Area Chair (Resources and Evaluation) in NAACL 2024 and ACL 2024. 
I'm also a PC member in AAAI 2024, NeurIPS 2024, COLM 2024, and ECAI 2024, and the reviewer for the Journal of IEEE Transactions on Audio, Speech, and Language Processing and the International Journal of Social Robotics.

You can find my CV here: [Feng Jiang's Curriculum Vitae](../assets/Curriculum_Vitae.pdf).

I have written the [Guidelines for Developing Core Competencies for Graduate Students](https://docs.qq.com/slide/DUnRncXZBbmF0eENs) in Chinese, which will be updated with my practice.
Here are some [personal guidelines](https://blog.csdn.net/qq_35082030/category_12959319.html) I've written for how to write an ACL Series Paper for reference.
﻿
[Email](mailto:jiangfeng@suat-sz.edu.cn) / [Github](https://github.com/fjiangAI) / [CSDN](https://fjiang.blog.csdn.net/)
﻿
If you want to discuss with me, you can email me and find a proper time slot for you and me by clicking the button below.


<!-- Google Calendar Appointment Scheduling begin -->
<link href="https://calendar.google.com/calendar/scheduling-button-script.css" rel="stylesheet">
<script src="https://calendar.google.com/calendar/scheduling-button-script.js" async></script>
<script>
(function() {
  var target = document.currentScript;
  window.addEventListener('load', function() {
    calendar.schedulingButton.load({
      url: 'https://calendar.google.com/calendar/appointments/schedules/AcZssZ23eVHHaTKhxXnb4htUtCRGyS2WRZAW1ZEK64TDZHZMT8sU3T6QtAypMrxYEWGqdcVc0WyFfypP?gv=true',
      color: '#039BE5',
      label: 'Book an appointment',
      target,
    });
  });
})();
</script>
<!-- end Google Calendar Appointment Scheduling -->


# [🔬 **Research Area**]

- LLM model: [Phoenix](https://github.com/FreedomIntelligence/LLMZoo), [HuatuoGPT](https://github.com/FreedomIntelligence/HuatuoGPT), [HuatuoGPT-II](https://github.com/FreedomIntelligence/HuatuoGPT-II)
- LLM Benchmark: [SDAK](https://github.com/FreedomIntelligence/SDAK), [CMB](https://github.com/FreedomIntelligence/CMB)
- LLM optimization: [Data Section](https://arxiv.org/pdf/2406.14115), [TS-align](https://arxiv.org/pdf/2405.20215), [FLR](https://arxiv.org/pdf/2409.13948)
- User Modeling: [PlatoLM](https://github.com/FreedomIntelligence/ReaLM), [USP](https://github.com/wangkevin02/USP)
- Application of LLM:[MMAPIS](https://github.com/fjiangAI/MMAPIS), [HTTP](https://github.com/FreedomIntelligence/ChatGPT-Detection-PR-HPPT), [HNDC](https://arxiv.org/pdf/2410.14259), [GrammarGPT](https://github.com/FreedomIntelligence/GrammarGPT)
- Discourse Parsing: [UMLF](https://github.com/Jeff-Sue/URT), [CPTS](https://github.com/fjiangAI/CPTS), [an empirical study for ChatGPT in discourse analysis of dialogue](https://github.com/yxfanSuda/GPTforDDA)




# [✨ **Latest News**]

[05/24/25] 🎉🎉🎉 We achieve the Top2 of DSTC-12 Track 2：Controllable Conversational Theme Detection.

[05/15/25] 🎉🎉🎉 We have one paper accepted by the ACL.

[01/23/25] 🎉🎉🎉 We have one paper accepted by the NAACL.

[01/20/25] 🎉🎉🎉 We have one paper accepted by the WWW.

[12/10/24] 🎉🎉🎉 We have one paper accepted by the Technical Track at AAAI.

[10/18/24] We released our HNDC, A fine-grained AI-generated text detector, and its [technique report](https://arxiv.org/pdf/2410.14259). 

[09/20/24] 🎉🎉🎉 We have two papers accepted as the main conference or Findings of EMNLP.

[09/20/24] We released our FLR, A reward model taking follow-up likelihood as the reward signals and its [technique report](https://arxiv.org/pdf/2409.13948). 

[07/10/24] 🎉🎉🎉 We have one paper accepted as the main conference of COLM.

[06/20/24] We released our Rethinking on Data Selection for Fine-Tuning Large Language Models and its [technique report](https://arxiv.org/pdf/2406.14115).

[06/16/24] We released our A Study on Judgement Bias on Humans and LLMs and its [technique report](https://arxiv.org/pdf/2402.10669).

[05/30/24] We released our TS-Align, A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models (TS-align) and its [technique report](https://arxiv.org/pdf/2405.20215).

[05/30/24] We released our [UMLF](https://github.com/Jeff-Sue/URT), an unsupervised mutual learning framework for discourse parsing and topic segmentation and its [technique report](https://arxiv.org/pdf/2405.19799).

[05/16/24] 🎉🎉🎉 We have one paper accepted as the main conference of ACL.

[03/26/24] We released our [CPTS](https://github.com/fjiangAI/CPTS), a Chinese paragraph-level topic structure corpus and its [technique report](https://arxiv.org/pdf/2305.14790).

[03/15/24] 🎉🎉🎉 We have one paper accepted as the main conference of NAACL.

[03/05/24] We made [an empirical study for ChatGPT in discourse analysis of dialogue](https://github.com/yxfanSuda/GPTforDDA) and released its [technique report](https://arxiv.org/pdf/2305.08391).

[02/20/24] 🎉🎉🎉 We have two papers accepted as the main conference of COLING.

[01/16/24] We released our [MMAPIS](https://github.com/fjiangAI/MMAPIS), A open-sourced Multi-Modal Automated Academic Papers Interpretation System, and its [technique report](https://arxiv.org/abs/2401.09150).

[11/16/23] We released our upgrade of HuatuoGPT to [HuatuoGPT-II](https://github.com/FreedomIntelligence/HuatuoGPT-II), and its [technique report](https://arxiv.org/abs/2311.09774).

[11/16/23] We released our [SDAK](https://github.com/FreedomIntelligence/SDAK), a self-diagnostic atomic knowledge benchmark for popular Chinese medical foundation models, and its [technique report](https://arxiv.org/abs/2310.11722).

[10/06/23] 🎉🎉🎉 We have three papers accepted as the main conference or Findings of EMNLP.

[08/23/23] We released our [PlatoLM](https://github.com/FreedomIntelligence/ReaLM), a user-simulator-based LLM, and its [technique report](https://arxiv.org/abs/2308.11534v1).

[08/21/23] We released our [CMB](https://github.com/FreedomIntelligence/CMB), a Comprehensive multi-level assessment for medical knowledge, and its [technique report](https://arxiv.org/abs/2308.08833).

[07/24/23] We released our [HTTP](https://github.com/FreedomIntelligence/ChatGPT-Detection-PR-HPPT), a ChatGPT-generated text detector checking the ChatGPT-involved degree, and its [technique report](https://arxiv.org/abs/2307.11380).

[06/26/23] We released our [GrammarGPT](https://github.com/FreedomIntelligence/GrammarGPT) and its [technique report](https://arxiv.org/abs/2307.13923).

[06/09/23] 🎉🎉🎉 We built the GrammarGPT and got the Third Prize in [NLPCC2023 Shared Task 1:  Chinese Grammatical Error Correction](https://github.com/masr2000/NaCGEC).

[05/26/23] We released our Medical LLM: [HuatuoGPT](https://github.com/FreedomIntelligence/HuatuoGPT) and its [technique report](https://arxiv.org/abs/2305.15075).

[04/16/23] We released our across languages LLM: [Phoenix](https://github.com/FreedomIntelligence/LLMZoo) and its [technique report](https://arxiv.org/abs/2304.10453).

[01/13/23] 🎉🎉🎉 We got the First Prize in the summarization track of [CAIL 2022](http://cail.cipsc.org.cn/task_summit.html?raceID=4&cail_tag=2022).

# [📚 **Representative Work**]

Kuang Wang, Xianfei Li, Shenghao Yang, Li Zhou, **Feng Jiang***, Haizhou Li: Know You First and Be You Better: Modeling Human-Like User Simulators via Implicit Profiles. ACL 2025. (**CCF-A**)

Chen Zhang, Dading Chong, **Feng Jiang***, Chengguang Tang, Anningzhe Gao, Guohua Tang, Haizhou Li: Aligning Language Models Using Follow-up Likelihood as Reward Signal. AAAI 2025. (**CCF-A**)

Chuyi Kong, Yaxin Fan, Xiang Wan, **Feng Jiang***, Benyou Wang: PlatoLM: Teaching LLMs in Multi-Round Dialogue via a User Simulator. ACL 2024: 7841–7863. (**CCF-A**)

**蒋峰**, 范亚鑫, 褚晓敏, 李培峰, 朱巧明. 英汉篇章结构分析研究综述. 软件学报,2023,34(09):4167-4194. 

**Feng Jiang**, Yaxin Fan, Xiaomin Chu, Peifeng Li, Qiaoming Zhu, Fang Kong: Hierarchical Macro Discourse Parsing Based on Topic Segmentation. In Proceedings of the Conference on Artificial Intelligence (AAAI 2021): 13152-13160. (**CCF-A**)

Zihao Chen, Li Zhou, **Feng Jiang**, Benyou Wang, Haizhou Li. Beyond Binary: Towards Fine-Grained LLM-Generated Text Detection via Role Recognition and Involvement Measurement. WWW 2025. (**CCF-A**)

Ziche Liu, Rui Ke, Yajiao Liu, **Feng Jiang***, Haizhou Li. Take the essence and discard the dross: A Rethinking on Data Selection for Fine-Tuning Large Language Models. NAACL 2025. (**CCF-B**)

**Feng Jiang**, Weihao Liu, Xiaomin Chu, Peifeng Li, Qiaoming Zhu, Haizhou Li: Advancing Topic Segmentation and Outline Generation in Chinese Texts: The Paragraph-level Topic Representation, Corpus, and Benchmark. COLING 2024: 495-506. (**CCF-B**)

**Feng Jiang**, Yaxin Fan, Xiaomin Chu, Peifeng Li, Qiaoming Zhu: Not Just Classification: Recognizing Implicit Discourse Relation on Joint Modeling of Classification and Generation. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP 2021): 2418-2431. (**CCF-B**)

**Feng Jiang**, Xiaomin Chu, Peifeng Li, Fang Kong, Qiaoming Zhu: Chinese Paragraph-level Discourse Parsing with Global Backward and Local Reverse Reading. In Proceedings of the 28th International Conference on Computational Linguistics (COLING 2020): 5749-5759. (**CCF-B**)

**Feng Jiang**, Sheng Xu, Xiaomin Chu, Peifeng Li, Qiaoming Zhu, Guodong Zhou: MCDTB: A Macro-level Chinese Discourse TreeBank. In Proceedings of the 27th International Conference on Computational Linguistics (COLING 2018): 3493-3504. (**CCF-B**)

Yaxin Fan, **Feng Jiang***, Peifeng Li, Haizhou Li: Uncovering the Potential of ChatGPT for Discourse Analysis in Dialogue: An Empirical Study. COLING 2024: 16998-17010. (**CCF-B**)

Yaxin Fan, **Feng Jiang**, Peifeng Li, Fang Kong, and Qiaoming Zhu. 2023. Improving Dialogue Discourse Parsing via Reply-to Structures of Addressee Recognition. EMNLP 2023: 8484–8495. (**CCF-B**)

Yaqiong He, **Feng Jiang**, Xiaomin Chu, Peifeng Li: Automated Chinese Essay Scoring from Multiple Traits. COLING 2022: 3007-3016. (**CCF-B**)

Xiaomin Chu, **Feng Jiang**, Yi Zhou, Guodong Zhou, Qiaoming Zhu: Joint Modeling of Structure Identification and Nuclearity Recognition in Macro Chinese Discourse Treebank. COLING 2018: 536-546. (**CCF-B**) (Best Paper Honorable Mention).

Zhiguang Gao, **Feng Jiang**, Xiaomin Chu, Peifeng Li. Adversarial Fine-grained Fact Graph for Factuality-oriented Abstractive Summarization. NLPCC 2022. (**CCF-C**) (**Best Student Paper**)

Yaxin Fan, **Feng Jiang***, Peifeng Li, Haizhou Li: GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning. NLPCC 2023: 69-80. (**CCF-C**)

Lingyi Yang, **Feng Jiang***, Haizhou Li: Is chatgpt involved in texts? measure the polish ratio to detect chatgpt-generated text. APSIPA Transactions on Signal and Information Processing, 2023, 13(2) (**JCR Q2**).

**Hongbo Zhang#**, **Junying Chen#**, **Feng Jiang#**, Fei Yu, Zhihong Chen, Guiming Chen, Jianquan Li, Xiangbo Wu, Zhiyi Zhang, Qingying Xiao, Xiang Wan, Benyou Wang, Haizhou Li:
HuatuoGPT, Towards Taming Language Model, to Be a Doctor. EMNLP (Findings) 2023: 10859-10885.

Chen Zhang, Chengguang Tang, Dading Chong, Ke Shi, Guohua Tang, **Feng Jiang***, Haizhou Li. TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models. EMNLP (Findings) 2024: 8926-8946.
